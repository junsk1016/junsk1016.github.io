---
layout: single
title: "Video Transformer Network ë¦¬ë·°"
categories:
  - DeepLearning
classes: wide
tags:
  - jeykll
  - github
  - Minimalmistakes
  - blog
  - DeepLearning
use_math: true
comments: true
---

###### Video Transformer Network ë¦¬ë·°  

#### ë…¼ë¬¸ ë‹¤ìš´ ë§í¬  
https://arxiv.org/pdf/2102.00719.pdf  

## Abstract  
Video Transformer Network ì œì•ˆ  
  + ì „ì²´ Video sequence informationì— attentioní•˜ì—¬ classificationí•˜ëŠ” ë°©ì‹  
  + 2D spatial networkì—ì„œ êµ¬ì¶•  
  + ê¸°ì¡´ì˜ sota modelë³´ë‹¤  
    - 16.1ë°° ë¹ ë¥¸ í•™ìŠµ ì‹œê°„  
    - 5.1ë°° ë¹ ë¥¸ inference ì‹œê°„  
    - single end-to-end passë¥¼ í†µí•´ 1.5ë°° ì ì€ GFLOPs  
  + Dataset : Kinetics-400  

## Introduction  
+ ConvNetì€ ë§ì€ ë¶„ì•¼ì—ì„œ sotaì˜ ê²°ê³¼ë¥¼ ê°€ì ¸ì™”ì§€ë§Œ, ìµœê·¼ì—ëŠ” Transformer-based modelì´ ë§ì€ ë¶„ì•¼ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ê°€ì ¸ì˜´.  
+ ê¸°ì¡´ì˜ temporal dimension ë¥¼ input clipì— straightë¡œ ì¶”ê°€í•œ ê²ƒê³¼ëŠ” ë‹¬ë¦¬ ìš°ë¦¬ëŠ” 3D netowrkì—ì„œ ë²—ì–´ë‚˜ëŠ” ê²ƒì— ì´ˆì ì„ ë§ì¶¤  
+ sota 2D ì•„í‚¤í…ì²˜ì—ì„œ spatial feature í•™ìŠµí•˜ê³  attention mechanismì„ ì‚¬ìš©í•´ data flow ì— temporal informationë¥¼ ì¶”ê°€  
+ ê¸°ì¡´ì˜ video recognition ì—ì„œëŠ” 10ì´ˆë„ ê¸¸ì–´ì„œ 2ì´ˆë¡œ ë‚˜ëˆ ì„œ í•™ìŠµí•˜ëŠ”ë° ëª‡ ì‹œê°„ì—ì„œ ëª‡ ë¶„ì§œë¦¬ ì˜ìƒì„ ìˆ˜ ì´ˆì˜ snippet ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì€ ì§ê´€ì ì´ì§€ ì•ŠìŒ  
+ VTNì˜ temporal processing componentëŠ” Longformer ê¸°ë°˜ì„
+ ì œì•ˆí•˜ëŠ” framework's structure component  
  - 2D Spatial backboneì€ ì•„ë¬´ê±°ë‚˜ ìƒê´€ ì—†ìŒ
  - Attention-based module  
    + more layer, more head í•´ë„ ìƒê´€ ì—†ìŒ  
    + long sequenceê°€ ê°€ëŠ¥í•œ transformer modelì´ë©´ ìƒê´€ ì—†ìŒ  
  - Classification headë¥¼ ë³€ê²½í•˜ì—¬ ë‹¤ë¥¸ video-based task ì‚¬ìš© ê°€ëŠ¥  

## Related Network  
#### Spatial-Temporal Network  
+ 3D ConvNet, Two-stream architecture, I3D  
+ Non-local Neural Network  
  - Self-attentionì— ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ëŠ” ìˆì§€ë§Œ ì§§ì€ í´ë¦½ì— í•œì •ì ì´ê¸° ë•Œë¬¸ì— FBO(Feature Bank Operator)ê°€ ì œì•ˆë˜ì—ˆì—ˆë‹¤  
  - FBOëŠ” long-term featureê°€ í•„ìš”í•˜ê³ , feature extraction backboneì˜ end-to-end trainingì„ ì§€ì›í•  ë§Œí¼ íš¨ìœ¨ì ì´ì§€ ì•ŠìŒ  
+ SlowFast  
+ X3D  

#### Transformer in computer vision  
+ NLPì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„  
+ Deep ConvNetì—ì„œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„  
  - Image classification : ViT, DeiT  
  - Object detection and panoptic segmentation : DETR  
  - Video instance segmentation : VisTR  

#### Applying Transformer on long sequences  
+ BERT & RoBERTa
  - Based language representation model, large unlabeled textì—ì„œ í•™ìŠµí•˜ê³  target taskì— ëŒ€í•´ fine-tuning  
+ BERT ëª¨ë¸ì´ë‚˜ ì¼ë°˜ì ì¸ transformer model ì˜ ë‹¨ì 
  - ê¸´ sequence ë¥¼ ì²˜ë¦¬í•˜ëŠ” ëŠ¥ë ¥  : $ğ‘‚(n^{2})$ ì˜ ë³µì¡ë„ë¥¼ ê°€ì§€ëŠ” self-attention ì—°ì‚°
+ Longformer  
  - $ğ‘‚(n)$ ì˜ ë³µì¡ë„ë¥¼ ê°€ì§€ëŠ” attention mechanism -> lengthy document ì²˜ë¦¬ ê°€ëŠ¥  
  - Sliding windowë¡œ ì²˜ë¦¬ë˜ëŠ” local-context self-attention + task-specific global attention  
+ Stacking up multiple sindowed attention layer : larger receptive field ë¥¼ ê°€ì§  
  - ë”°ë¼ì„œ ì „ì²´ sequence ì—ì„œ ì •ë³´ë¥¼ integrate ê°€ëŠ¥  
+ Global attention part ëŠ” pre-selected token(ì˜ˆ: [CLS] í† í°)ì— ì´ˆì ì„ ë§ì¶”ê³  input sequenceì—ì„œ ë‹¤ë¥¸ ëª¨ë“  tokenì— ì£¼ì˜ë¥¼ ê¸°ìš¸ì¼ ìˆ˜ ìˆìŒ  

## Video Transformer network  

<p align="center"><img src="/img/VTN-Fig1.jpg"></p>  

#### Video Transformer Network (VTN)  
+ frame level ì—ì„œ objective task head ê¹Œì§€ single stream ìœ¼ë¡œ ë™ì‘  
+ 3ê°€ì§€ consecutive partë¡œ êµ¬ì„±  
  - 2D spatial feature extraction  
  - Temporal attention-based encoder  
  - Classification MLP head  
+ Memory ë¬¸ì œë¡œ ì¸í•œ 3ê°€ì§€ inference ë°©ë²• ì œì•ˆ  
  - end-to-end ë°©ì‹ìœ¼ë¡œ ì „ì²´ video ì²˜ë¦¬  
  - video ë¥¼ chunk ì²˜ë¦¬ í›„ feature ì¶”ì¶œ í›„temporal attention-based encoder ì— ì ìš©  
  - ëª¨ë“  frame feature ë¥¼ ì¶”ì¶œ í›„ ë‹¤ìŒ temporal encoderì— ì…ë ¥  

#### Spatial backbone (2D spatial feature extraction)
+ Feature extraction module  
+ deep/shallow , pre-trained/not , conv/transformer-based , weight ê³ ì •/í•™ìŠµ ê³¼ ìƒê´€ ì—†ëŠ” 2D image any network ì‚¬ìš© ê°€ëŠ¥  

#### Temporal attention-based encoder  
+ Transformer : ë™ì‹œì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” token ì˜ ìˆ˜ê°€ ì œí•œë¨  
  - Video ì™€ ê°™ì€ ê¸´ ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³ , distant information ì˜ ì—°ê²°ì„ incorporate í•˜ëŠ” ëŠ¥ë ¥ ì œí•œí•  ìˆ˜ ìˆìŒ  
+ Inference ë™ì•ˆ ì „ì²´ video ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ë²• ì œì•ˆ -> longformer ì‚¬ìš©  
  - Linear computation complexity ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” sliding window attention ì‚¬ìš©  
  - Encoder ì˜ input ì€ spatial backbone ì—ì„œ ë‚˜ì˜¨ feature vector  
    + Feature vector ëŠ” 1D token ì—­í• ì„ í•¨  
+ BERT ì²˜ëŸ¼ CLS(special classification) token ì„ feature sequence ì•ì— ì¶”ê°€  
  - 1) Longformer layer ë¥¼ í†µí•´ sequence ë¥¼ í†µê³¼í•œ í›„  
  - 2) ì´ CLS token ê³¼ ê´€ë ¨ëœ feature ì˜ final state ë¥¼ ë¹„ë””ì˜¤ì˜ ìµœì¢… representation ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  ì§€ì •ëœ classification task headì— ì ìš©   
  - LongformerëŠ” ë˜í•œ ê·¸ íŠ¹ë³„í•œ [CLS] í† í°ì— ëŒ€í•œ global attentionì„ ìœ ì§€  

#### Classification MLP head  
+ Final predicted category ë¥¼ ìœ„í•´ MLP head ì‚¬ìš©  
+ MLP head ëŠ” GELU activation function ê³¼ dropout ì„ í¬í•¨  
+ Input token representation ì€ ë¨¼ì € layer normalization  

#### Looking beyond a short clip context
+ ì¼ë°˜ì ì¸ ì ‘ê·¼ ë°©ì‹ì¸ 3D Conv ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬ëŠ” ì‘ì€ spatial scale ê³¼ ì ì€ ìˆ˜ ì˜ frame ì—ì„œ ë™ì‘  

## Video Action Recognition with VTN  

#### 2D feature extractor backbone ì‹¤í—˜  

<p align="center"><img src="/img/VTN-Fig1.jpg"></p>  

#### Implementation Details  
+ Longformer ì™€ MLP classification head : í‰ê·  0, ë¶„ì‚° 0.02 ì¸ ì •ê·œ ë¶„í¬ì—ì„œ random ì´ˆê¸°í™”  
+ SGD optimizer  
+ Batch size : 16(ViT-B-VTN), 32(R50/101-VTN)  
+ Learning rate : $10^{-3}$  

<p align="center"><img src="/img/VTN-Fig3.jpg"></p>  

## Experiments  
+ Kinetics-400 datasetì— ëŒ€í•´ ì‹¤í—˜  

<p align="center"><img src="/img/VTN-Fig4.jpg"></p>  

<p align="center"><img src="/img/VTN-Fig5.jpg"></p>  

## Conclusion  
+ Transformer-based framework ì œì•ˆ  
+ í…ŒìŠ¤íŠ¸ ì‹œ, long videoë¥¼ ì²˜ë¦¬ ê°€ëŠ¥  
+ í˜„ì¬ì˜ ë°ì´í„°ì…‹ì€ long-term video ì²˜ë¦¬ ëŠ¥ë ¥ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ”ë° ì´ìƒì ì´ì§€ ì•ŠìŒ  
+ ë¯¸ë˜ì— ì í•©í•œ ë°ì´í„°ì…‹ì´ êµ¬ì¶•ëœë‹¤ë©´ VTNê°™ì€ ëª¨ë¸ì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¼ ê²ƒì„  
