---
layout: single
title: "FaraPy: An Augmented Reality Feedback System for Facial Paralysis using Action Unit Intensity Estimation 리뷰"
categories:
  - DeepLearning
classes: wide
tags:
  - jeykll
  - github
  - Minimalmistakes
  - blog
  - DeepLearning
use_math: true
comments: true
---

###### FaraPy: An Augmented Reality Feedback System for Facial Paralysis using Action Unit Intensity Estimation 리뷰  

#### 논문 다운 링크  
https://dl.acm.org/doi/10.1145/3472749.3474803  

#### Keywords : Facial palsy, Facial paralysis, Augmented Reality, Lightweight models, Facial action unit detection, Action unit intensity  

## Abstract  
안면마비  
+ 정서적 고통 초래, 심리-사회적 웰빙에 영향을 미치는 기능적-미적 결함 유발  

기존의 대표적인 치료 방법으로는 거울 치료가 있다. 하지만 단점들이 존재하므로 아래의 방법을 제안한다.  

제안하는 것  
+ 실시간 피드백을 제공하며, 시간 경과에 따라 사용자의 진행 상황을 추적함  
+ 안면마비를 위한 최초의 모바일 증강 현실 거울 치료 시스템인 FaraPy 제안  
  - 안면 운동할 때 근육의 활성화 정도를 감지  
  - facial action unit intensity 를 detect 하기 위한 benchmark data 에서 최신 모델보다 성능 우수  
  - 20명의 사용자를 대상으로 거울 치료보다 제안하는 시스템에 대한 선호도 보여줌  

## Introduction  
안면마비는 안면 신경(Facial nerve) 의 손상으로 인해 발생한다. 물리 치료의 경우 맞춤형 안면 운동과 거울치료를 병행하면서 한다. 하지만 거울 치료의 단점들은 아래와 같다.  
+ 사용자의 동기 감소, 의미있는 피드백 및 근육 운동 부족, 거울 노출 불안, 시간 경과에 따른 진행 상황 추적 불가  
그래서 우리는 Backend 에 새로운 딥러닝 모델이 포함된 Mobile AR system인 FaraPy를 제안한다.  
+ 모델 : LW-FAU(Light Weight Facial Activation Unit)  
  - input은 사용자의 카메라이며, 안면 근육의 activation 및 intensity를 감지  
+ AR interface  
  - 감지된 안면 근육 활성화에 대한 실시간 피드백을 사용자에게 제공  

## Related Work
크게 3가지에 대해 설명한다. 거울 치료, AR, Facial Action Unit Intensity Estimation.  
거울 치료  
+ 물론 효과적인 보조 치료  
+ 마비된 쪽을 거울로 가리면, 노출 불안을 예방하지만 마비 근육에 대한 생체 피드백 받을 수 없음  
+ 사용자는 영향을 받는 쪽으로 기울어지는 경향이 있으며, mirror 축과 정렬되지 않는 경우가 많음  

AR(Augmented Reality) in Healthcare  
+ AR이란 가상 객체와 정보를 현실 세계에 추가하는 것  
+ 제안하는 시스템은 어떠한 장비나 마커의 착용을 요구하지 않음  

Faical Action Unit Intensity Estimation  
+ FACS(Facial Action Coding System) : 얼굴 동작 코딩 시스템  
  - 44개의 AU(Action Unit)을 사용하여 5가지 등급으로 코딩된 AUI 와 관련된 얼굴 동작 설명  
  - 5가지 등급이란 0:해당 표정을 전혀 짓지 않음 ~ 5: 해당 표정을 매우 짓고 있음 으로 코딩됨  
  - 얼굴 동작 예시 : Inner Brow Raiser, Lid Droop, Blink, Cheek Puffer, Dimpler 등  

## System Design  

##### Pipeline  

<p align="center"><img src="/img/FaraPy_1.jpg"></p>  

+ LW-FAU model 에서 처리 후 AR에서 사용자를 위해 시각화되는 실시간 피드백 생성  
+ 계산된 피드백은 사용자의 얼굴에 대한 확대 및 활성화된 안면 근육의 데이터를 시각화로 표시  

##### Light Weight Facial Activation Unit model (LW-FAU)  
+ 모바일 장치에서 실시간으로 one-sided AUI 를 최종값으로 제공하는 최초의 모델  
+ 모델 설계의 특징
  - 얼굴의 좌우측 각 측면에 있는 근육에 대해 독립적으로 AU 와 AUI 를 감지하는 것  
  - 모델을 모바일 장치에서 실시간으로 실행하는 것  
+ Depth-wise separable convolution  
  - MobileNet에서 사용, depthwise + point-wise convolution  
+ Multi-Task Learning  
  - task간의 유사점/차이점을 활용하여 공통 모델을 통해 여러 task를 동시에 학습  
+ FAU-Net에서 얼굴을 반으로 나누어 heatmap 생성
  - $AUI_{Final} = \frac{AUI_{LHeatmap} + AUI_{RHeatmap}}{2}$  
  - benchmark와 개인의 새 dataset에 안면마비 label을 지정하는데 사용  

<p align="center"><img src="/img/FaraPy_2.jpg"></p>  

+ Knowledge Distillation  
  - 학습된 큰 네트워크를 사용해 작은 네트워크를 학습하는 모델 압축 아이디어  
  - Teacher model로 FAU-Net 사용, 학습할 때 MAE로 error 계산  

<p align="center"><img src="/img/FaraPy_3.jpg"></p>  

##### Dataset  
+ DISFA
  - 27명의 성인, 포즈가 없는 표정 benchmark  
  - FAU와 LW-FAU의 성능 비교를 위해 FAU-Net 의 중간 prdiction을 중간 목표값으로 레이블 지정  
+ 테스트를 위해 새로운 FIFA dataset 생성  
  - 안면마비 개인의 비디오 데이터로 만듦  
  - Label은 DISFA와 동일하게 지정  
  - 5가지 안면 운동을 순차적으로 수행하는 20명(16여,4남)의 5분 비디오  

##### Augmented Reality Interface  
+ 얼굴 비디오 데이터에서 각 측면(왼/오)에 대한 AUI를 독립적으로 추정
+ 5개의 AU(Cheek Raiser, Upper Lip Raiser, Lip Corner Puller, Dimpler, Chin Raiser)로부터 10개의 unilateral AUI float value가 계산됨  
+ Model의 prediction 이후 어느 쪽이 마비되었는지 확인  
  - 한쪽 안면마비의 경우 (3)처럼 전반적인 하부 근육 활성화를 기반으로 영향 받는 쪽 식별
<p align="center"><img src="/img/FaraPy_4.jpg"></p>  

+ 얼굴 운동의 목표는 대칭 얼굴 표정을 만들기 위해 작은 얼굴 근육을 시각적으로 식별할 수 있는 제어를 생성하는 것  
  - AUI의 출력을 사용해 각 측면의 활성화 비율을 계산하여 사용자에게 실시간으로 시각화  
<p align="center"><img src="/img/FaraPy_5.jpg"></p>  
  - AUI 는 0~5까지의 양수이므로 dRation 는 양수이지만 0~1의 작은 양수값 가능함. 전체 얼굴에 대한 전체 대칭 비율 점수 symmRatio 는 아래와 같음  
<p align="center"><img src="/img/FaraPy_6.jpg"></p>  
+ AR feedback 은 근육 움직임과 AUI에 대한 정보를 제공
  - 근육 필터 형태로 사용자의 얼굴에 정량화/시각화  
  - 활성화 정도를 막대로 표시 (활성화 정도에 대한 피드백을 색깔로 제공)  
<p align="center"><img src="/img/FaraPy_7.jpg"></p>  
+ Muscle education 을 제공하기 위해 3D AR facial muscle filter 제작  
  - 마스크로 마비된 얼굴 가려 불안감 줄임 + 근육 활성화 정도 제공  
+ Score system 동작(근육 활성화 정도로 점수 부여)  
  - 대칭적으로 활성화(= dRatio 가 -0.1~0.2) 면 녹색 바 -> 1점 획득
  - 과활성화(= dRatio 가 -1.0~-.01)면 보라색 바 -> 점수 획득 X
  - 비활성화(=dRatio 가 0.2~1.0)면 파란색 바 -> 점수 획득 X

## Technimal Evaluation  
+ Benchmark data와의 비교(FAU-Net)  
  - $MAE_{\mu}=0.14, ICC_{\mu}=0.77$ 로 sota FAU-Net보다 우수
    + 하지만 FAU-Net은 양면 AUI라서 간접적인 비교할 수 밖에 없었음  
  - 그러나 $p < 0.05$ 에 대한 $AUI_{\mu}$ 에서 유의미한 차이 찾지 못함  
    + 그래도 Knowledge distillation 을 사용했으므로 실시간 사용에 더 적합  
<p align="center"><img src="/img/FaraPy_8.jpg"></p>  

## User Evaluation  
+ Zoom을 사용하였고, 안면운동을 실시한 후 설문조사함  
  - 안면운동 : 미소 짓기, 턱 벌리고 닫기, 아야(A-O-I) 하기, 이를 악물기, 크게 하품하기  
+ 설문조사 내용  
  - 매력성 : 제품에 대한 전반적인 인상, 시스템에 마음에 드는지?
  - 명료성 : 시스템에 익숙해지기 쉬운가? 배우기 쉬운가? 시스템이 이해하기 쉽고 명료한가?
  - 효율성 : 효율적이고 빠름? 시스템이 입력에 대해 빠르게 반응하는가?
  - 신뢰성 : interaction 을 control 할 수 있다고 느끼나? 할 때 안전하다고 느끼나?
  - 자극 : 흥미진진하거나 동기가 부여되는가?
  - 새로움 : 시스템이 혁신적이고 창의적인가? 관심을 사로잡는가?
<p align="center"><img src="/img/FaraPy_9.jpg"></p>  

## Limitations and Future Work  
+ Lack of FP benchmark Models and Data Sets  
  - One-side AUI value 를 가진 dataset 이 존재하지 않음  
  - 따라서 FAU-Net으로 FIFA dataset을 labeling
  - 이 말은 FAU-Net의 성능에 따라 dataset의 label이 달라지게 됨  
+ Future Works  
  - 얼굴의 양쪽 절반을 독립적으로 고려하여 보다 세분화된 수준에서 안면 근육 활성화를 설명하는 포괄적인 시스템을 구축할 필요  

## Conclusion  
+ 안면 마비가 있는 개인을 위한 안면 운동에 대한 실시간 피드백을 제공하는 최초의 모바일 증강 현실 거울 치료 시스템인 FaraPy를 제시  
  - 안면 운동 치료의 목표인 얼굴 표정 대칭에 대한 피드백을 제공하여 FP가 있는 개인이 집에서 치료를 계속할 수 있도록 함  
  - 양측 안면 근육 활성화를 감지하는 기존의 모든 모델과 달리 우리 모델은 안면 마비 환자에게 필요한 얼굴의 각 측면에 대해 독립적으로 근육 활성화를 감지  

+ 안면 마비가 있는 20명의 참가자 대상 결과  
  - 기존의 거울 요법 기반 바이오피드백보다 AR에 대한 높은 만족도와 선호도를 보여줌  
